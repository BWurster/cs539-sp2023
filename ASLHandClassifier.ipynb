{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c8c944d-5771-416b-bf6b-e6926915ad62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 20:01:00.918669: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-18 20:01:01.079621: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-18 20:01:01.081203: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-18 20:01:01.890994: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f57bea-e384-4490-b61b-414230665697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[..., :3], [3, 6, 1]).astype('int16')\n",
    "\n",
    "\n",
    "def brighten(regImages):\n",
    "    for ind in np.arange(len(regImages)):\n",
    "        regImages[ind] = np.clip(regImages[ind] + int(np.random.normal(scale=400)), 0, 2550)\n",
    "    return regImages\n",
    "\n",
    "\n",
    "def trainValTest(length, trainPer, valPer):\n",
    "    indices = np.arange(length)\n",
    "    np.random.shuffle(indices)\n",
    "    trainIndices = indices[0:int(trainPer*length)]\n",
    "    valIndices = indices[int(trainPer*length):int((trainPer + valPer)*length)]\n",
    "    testIndices = indices[int((trainPer + valPer)*length):]\n",
    "    return trainIndices, valIndices, testIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c07b5d3c-3867-4115-a5b2-f3b78fff2708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = r'data/asl_alphabet_train/asl_alphabet_train/'\n",
    "\n",
    "types = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V',\n",
    "         'W', 'X', 'Y', 'Z', 'space', 'del', 'nothing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5be56cd8-5737-4ea8-8b78-e3594d8451ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(types)):\n",
    "    file_list = os.listdir(path + types[i])\n",
    "    for file in file_list:\n",
    "        img = cv2.imread(path + types[i] + '/' + file)\n",
    "        images.append(img)\n",
    "        label = np.zeros(29)\n",
    "        label[i] = 1\n",
    "        labels.append(label)\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d93b0d64-2e52-4579-9502-af6ab1185183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainInds, valInds, testInds = trainValTest(len(labels), 0.8, 0.1)\n",
    "\n",
    "XTrain = images[trainInds]\n",
    "XTrain = brighten(XTrain)\n",
    "yTrain = labels[trainInds]\n",
    "\n",
    "XVal = images[valInds]\n",
    "yVal = labels[valInds]\n",
    "\n",
    "XTest = images[testInds]\n",
    "yTest = images[testInds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67f9ae17-ce0d-49c7-b4fa-5964166127be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 200, 200, 3)       78        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 100, 100, 3)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 100, 100, 5)       140       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 50, 50, 5)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 50, 50, 10)        460       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 25, 25, 10)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 5, 5, 10)          2510      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 250)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                12550     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 40)                2040      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 29)                1189      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,967\n",
      "Trainable params: 18,967\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(3, 5, padding='same', activation='relu', input_shape=(200, 200, 1)),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(5, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(10, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(10, 5, strides=5, padding='valid', activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(40, activation='relu'),\n",
    "    tf.keras.layers.Dense(29, activation='softmax')])\n",
    "\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7872b4aa-658c-4245-9186-ceb1368eb25b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e95ca200-fa5e-47b6-b695-fa72492e03d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 20:03:16.990050: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5736000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 20:03:51.012726: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 24000000 exceeds 10% of free system memory.\n",
      "2023-04-18 20:03:51.208096: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 21850000 exceeds 10% of free system memory.\n",
      "2023-04-18 20:03:51.208279: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 21850000 exceeds 10% of free system memory.\n",
      "2023-04-18 20:03:51.214227: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 26100000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1434/1434 [==============================] - 294s 204ms/step - loss: 3.3270 - accuracy: 0.0773 - val_loss: 2.8629 - val_accuracy: 0.1713\n",
      "Epoch 2/30\n",
      "1434/1434 [==============================] - 281s 196ms/step - loss: 2.1086 - accuracy: 0.3450 - val_loss: 1.3632 - val_accuracy: 0.5321\n",
      "Epoch 3/30\n",
      "1434/1434 [==============================] - 286s 199ms/step - loss: 1.1412 - accuracy: 0.6039 - val_loss: 0.8544 - val_accuracy: 0.6946\n",
      "Epoch 4/30\n",
      "1434/1434 [==============================] - 290s 202ms/step - loss: 0.8152 - accuracy: 0.7108 - val_loss: 0.6273 - val_accuracy: 0.7748\n",
      "Epoch 5/30\n",
      "1434/1434 [==============================] - 295s 206ms/step - loss: 0.6380 - accuracy: 0.7709 - val_loss: 0.5256 - val_accuracy: 0.8187\n",
      "Epoch 6/30\n",
      "1434/1434 [==============================] - 292s 204ms/step - loss: 0.5360 - accuracy: 0.8081 - val_loss: 0.4734 - val_accuracy: 0.8332\n",
      "Epoch 7/30\n",
      "1434/1434 [==============================] - 292s 204ms/step - loss: 0.4707 - accuracy: 0.8313 - val_loss: 0.4175 - val_accuracy: 0.8495\n",
      "Epoch 8/30\n",
      "1434/1434 [==============================] - 292s 204ms/step - loss: 0.4193 - accuracy: 0.8494 - val_loss: 0.3689 - val_accuracy: 0.8728\n",
      "Epoch 9/30\n",
      "1434/1434 [==============================] - 293s 204ms/step - loss: 0.3841 - accuracy: 0.8601 - val_loss: 0.4262 - val_accuracy: 0.8506\n",
      "Epoch 10/30\n",
      "1434/1434 [==============================] - 293s 205ms/step - loss: 0.3511 - accuracy: 0.8740 - val_loss: 0.2919 - val_accuracy: 0.8969\n",
      "Epoch 11/30\n",
      "1434/1434 [==============================] - 294s 205ms/step - loss: 0.3233 - accuracy: 0.8834 - val_loss: 0.3087 - val_accuracy: 0.8921\n",
      "Epoch 12/30\n",
      "1434/1434 [==============================] - 294s 205ms/step - loss: 0.3098 - accuracy: 0.8879 - val_loss: 0.3282 - val_accuracy: 0.8912\n",
      "Epoch 13/30\n",
      "1434/1434 [==============================] - 294s 205ms/step - loss: 0.2848 - accuracy: 0.8977 - val_loss: 0.2993 - val_accuracy: 0.8967\n",
      "Epoch 14/30\n",
      "1434/1434 [==============================] - 296s 206ms/step - loss: 0.2705 - accuracy: 0.9049 - val_loss: 0.2627 - val_accuracy: 0.9075\n",
      "Epoch 15/30\n",
      "1434/1434 [==============================] - 294s 205ms/step - loss: 0.2580 - accuracy: 0.9071 - val_loss: 0.2068 - val_accuracy: 0.9281\n",
      "Epoch 16/30\n",
      "1434/1434 [==============================] - 294s 205ms/step - loss: 0.2557 - accuracy: 0.9089 - val_loss: 0.2283 - val_accuracy: 0.9240\n",
      "Epoch 17/30\n",
      "1434/1434 [==============================] - 298s 207ms/step - loss: 0.2311 - accuracy: 0.9184 - val_loss: 0.2153 - val_accuracy: 0.9281\n",
      "Epoch 18/30\n",
      "1434/1434 [==============================] - 293s 204ms/step - loss: 0.2294 - accuracy: 0.9182 - val_loss: 0.2007 - val_accuracy: 0.9323\n",
      "Epoch 19/30\n",
      "1434/1434 [==============================] - 293s 204ms/step - loss: 0.2190 - accuracy: 0.9231 - val_loss: 0.2189 - val_accuracy: 0.9279\n",
      "Epoch 20/30\n",
      "1434/1434 [==============================] - 292s 204ms/step - loss: 0.2144 - accuracy: 0.9245 - val_loss: 0.1979 - val_accuracy: 0.9326\n",
      "Epoch 21/30\n",
      "1434/1434 [==============================] - 294s 205ms/step - loss: 0.2002 - accuracy: 0.9287 - val_loss: 0.2351 - val_accuracy: 0.9194\n",
      "Epoch 22/30\n",
      "1434/1434 [==============================] - 286s 199ms/step - loss: 0.1972 - accuracy: 0.9310 - val_loss: 0.1674 - val_accuracy: 0.9444\n",
      "Epoch 23/30\n",
      "1434/1434 [==============================] - 289s 201ms/step - loss: 0.1923 - accuracy: 0.9318 - val_loss: 0.2068 - val_accuracy: 0.9312\n",
      "Epoch 24/30\n",
      "1434/1434 [==============================] - 289s 202ms/step - loss: 0.1930 - accuracy: 0.9316 - val_loss: 0.1780 - val_accuracy: 0.9409\n",
      "Epoch 25/30\n",
      "1434/1434 [==============================] - 316s 220ms/step - loss: 0.1821 - accuracy: 0.9362 - val_loss: 0.2268 - val_accuracy: 0.9236\n",
      "Epoch 26/30\n",
      "1434/1434 [==============================] - 331s 230ms/step - loss: 0.1783 - accuracy: 0.9387 - val_loss: 0.2497 - val_accuracy: 0.9237\n",
      "Epoch 27/30\n",
      "1434/1434 [==============================] - 292s 203ms/step - loss: 0.1708 - accuracy: 0.9401 - val_loss: 0.1916 - val_accuracy: 0.9367\n",
      "Epoch 28/30\n",
      "1434/1434 [==============================] - 294s 205ms/step - loss: 0.1765 - accuracy: 0.9388 - val_loss: 0.1728 - val_accuracy: 0.9430\n",
      "Epoch 29/30\n",
      "1434/1434 [==============================] - 279s 194ms/step - loss: 0.1708 - accuracy: 0.9402 - val_loss: 0.1853 - val_accuracy: 0.9381\n",
      "Epoch 30/30\n",
      "1434/1434 [==============================] - 283s 197ms/step - loss: 0.1688 - accuracy: 0.9418 - val_loss: 0.1640 - val_accuracy: 0.9445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f706b902650>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(XTrain, yTrain, epochs=30, batch_size=50, validation_data=(XVal, yVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bf8df60-fa1e-422f-bc38-696b7579136a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: BenNN/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: BenNN/assets\n"
     ]
    }
   ],
   "source": [
    "net.save(\"BenNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d79bda9-3796-46fb-b9a3-9afc0fa92fef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net.save_weights('BenNNweights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c76051-ff08-4a48-a22f-b764da3fcf97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
